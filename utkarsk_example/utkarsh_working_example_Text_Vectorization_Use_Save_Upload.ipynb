{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w47A5xPdXp1W",
        "fTmjxD3k10sj",
        "X7NHPGuvcdm3",
        "F3wsbjvlW5bk",
        "GHr3M_p1ctKe",
        "ye1tSOhYdZeX",
        "Mcfd6oqiD9R_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w47A5xPdXp1W"
      },
      "source": [
        "# KERAS TEXT VECTORIZATION LAYER: USE, SAVE, AND UPLOAD\n",
        "\n",
        "**Author:** [Murat Karakaya](https://www.linkedin.com/in/muratkarakaya/)<br>\n",
        "**Date created:** 05 Oct 2021<br>\n",
        "**Last modified:** 24 Oct 2021<br>\n",
        "**Description:** This is a new part of the \"**[tf.keras.layers: Understand & Use](https://www.youtube.com/playlist?list=PLQflnv_s49v_7WIgOo9mVKptLZHyOYysD)**\" / \"[**tf.keras.layers: Anla ve Kullan**](https://www.youtube.com/playlist?list=PLQflnv_s49v9h85zD1_GDfTxZOrCWTDhp)\" series. In this part, we will build, adapt, use, save, and upload the Keras TextVectorization layer. \n",
        "\n",
        "We will download a [Kaggle Dataset](https://www.kaggle.com/savasy/multiclass-classification-data-for-turkish-tc32?select=ticaret-yorum.csv) in which there are 32 topics and more than 400K total reviews. \n",
        "In this tutorial, we will use this dataset for a multi class text classification task.\n",
        "\n",
        "Our **main aim** is to learn how to efectively use the Keras `TextVectorization` layer in practice.\n",
        "\n",
        "The tutorial has 5 parts:\n",
        "\n",
        "* **PART A: BACKGROUND**\n",
        "* **PART B: KNOW THE DATA**\n",
        "* **PART C: USE KERAS TEXT VECTORIZATION LAYER**\n",
        "* **PART D: BUILD AN END-TO-END MODEL**\n",
        "* **PART E: SUMMARY**\n",
        "\n",
        "\n",
        "At the end of this tutorial, we will cover:\n",
        "* What a Keras `TextVectorization` layer is\n",
        "* Why we need to use a Keras `TextVectorization` layer in Natural Languge Processing (NLP) tasks\n",
        "* How to employ a Keras `TextVectorization` layer in **Text Preprocessing**\n",
        "* How to integrate a Keras `TextVectorization` layer to a trained model\n",
        "* How to save and upload a Keras `TextVectorization` layer and a model with a Keras `TextVectorization` layer\n",
        "* How to integrate a Keras `TextVectorization` layer with **TensorFlow Data Pipeline** API (`tf.data`)\n",
        "* How to design, train, save, and load an End-to-End model using Keras `TextVectorization` layer\n",
        "\n",
        "**Accessible on:**\n",
        "* [YouTube in English](https://youtube.com/playlist?list=PLQflnv_s49v8Eo2idw9Ju5Qq3JTEF-OFW)\n",
        "* [YouTube in Turkish](https://youtube.com/playlist?list=PLQflnv_s49v8-xeTLx1QmuE-YkRB4bToF)\n",
        "* [Medium](https://kmkarakaya.medium.com/text-vectorization-use-save-upload-54d65945d222)\n",
        "* [Github pages](https://kmkarakaya.github.io/Deep-Learning-Tutorials/)\n",
        "* [Github Repo](https://github.com/kmkarakaya/Deep-Learning-Tutorials)\n",
        "* [Google Colab](https://colab.research.google.com/drive/1_hiUXcX6DwGEsPP2iE7i-HAs-5HqQrSe?usp=sharing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTmjxD3k10sj"
      },
      "source": [
        "# REFERENCES\n",
        "* [Keras Preprocessing layers by Keras.io](https://keras.io/api/layers/preprocessing_layers/)\n",
        "* [Text classification from scratch by Keras.io](https://keras.io/examples/nlp/text_classification_from_scratch/)\n",
        "* [TextVectorization layer by Keras.io](https://keras.io/api/layers/preprocessing_layers/text/text_vectorization/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7NHPGuvcdm3"
      },
      "source": [
        "# **PART A: BACKGROUND**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXnOwUb7oO0-"
      },
      "source": [
        "# 1 TERMS & CONCEPTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3wsbjvlW5bk"
      },
      "source": [
        "## 1.1 What is Text Vectorization?\n",
        "\n",
        "Text Vectorization is the process of converting text into numerical representation. \n",
        "\n",
        "There are many different techniques proposed to convert text to a numerical form such as:\n",
        "* One-hot Encoding (OHE)\n",
        "* Count Vectorizer\n",
        "* Bag-of-Words (BOW)\n",
        "* N-grams\n",
        "* Term Frequency\n",
        "* Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "* Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4cW26J5YnIR"
      },
      "source": [
        "## 1.2. What is Text Preprocessing?\n",
        "Text preprocessing is traditionally an important step for natural language processing (NLP) tasks. It transforms text into a more suitable form so that Machine Learning or Deep Learning algorithms can perform better.\n",
        "\n",
        "The main phases of Text preprocessing:\n",
        "* **Noise Removal** (cleaning) – Removing unnecessary characters and formatting\n",
        "* **Tokenization** – break multi-word strings into smaller components\n",
        "* **Normalization** – a catch-all term for processing data; this includes stemming and lemmatization\n",
        "\n",
        "\n",
        "Some of the common **Noise Removal** (cleaning) steps are:\n",
        "\n",
        "* Removal of Punctuations\n",
        "* Removal of Frequent words\n",
        "* Removal of Rare words\n",
        "* Removal of emojis\n",
        "* Removal of emoticons\n",
        "* Conversion of emoticons to words\n",
        "* Conversion of emojis to words\n",
        "* Removal of URLs\n",
        "* Removal of HTML tags\n",
        "* Chat words conversion\n",
        "* Spelling correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6LfU5Muatns"
      },
      "source": [
        "**Tokenization** is about splitting strings of text into smaller pieces, or “tokens”. Paragraphs can be tokenized into sentences and sentences can be tokenized into words. \n",
        "\n",
        "\n",
        "**Noise Removal** and **Tokenization** and  are staples of almost all text pre-processing pipelines. However, some data may require further processing through text **normalization**. Some of the common **normalization** steps are:\n",
        "* Upper or lowercasing\n",
        "* Stopword removal\n",
        "* Stemming – bluntly removing prefixes and suffixes from a word\n",
        "* Lemmatization – replacing a single-word token with its root\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MIVN5X4Di96"
      },
      "source": [
        "## 1.3. What is Keras Text Vectorization layer?\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKTqWoHWD0_a"
      },
      "source": [
        "`tf.keras.layers.TextVectorization` layer is one of the [Keras Preprocessing layers](https://keras.io/guides/preprocessing_layers/). \n",
        "\n",
        "We can preproces the input by using different libraries such as Python String library, or SciKit Learn library, etc. \n",
        "\n",
        "However, there are very important advantages using the [Keras Preprocessing layers](https://keras.io/guides/preprocessing_layers/):\n",
        "\n",
        "* You can build **Keras-native** input processing **pipelines**. These input processing pipelines can be used as **independent** preprocessing code in **non-Keras workflows**, combined directly with Keras models, and exported as part of a Keras SavedModel.\n",
        "\n",
        "* You can build and **export** models that are **truly end-to-end**: models that accept **raw data** (images or raw structured data) as input; models that handle feature **normalization** or feature value **indexing** on their own.\n",
        "\n",
        "Today, we will deal with the `tf.keras.layers.TextVectorization` layer which:\n",
        "* turns ***raw strings*** into an **encoded representation** \n",
        "* that representation can be read by an `Embedding` layer or `Dense` layer.\n",
        "\n",
        "That is, the `tf.keras.layers.TextVectorization` layer can be used in \n",
        "* **Text Preprocessing** and\n",
        "* **Text Vectorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FKitY3ahAx7"
      },
      "source": [
        "# 2. IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6TwpteGR7R"
      },
      "source": [
        "**IMPORTANT:** When I prepared this tutorial on 05 Oct 2021, the current version (2.6.0) of TF and Keras generate some **errors** in saving and uploading the **tf.keras.layers.TextVectorization layer**. \n",
        "\n",
        "However, the nightly version has no problem handling these operations.\n",
        "\n",
        "For more information about the bug, please see [here](https://github.com/keras-team/keras/issues/15443#issuecomment-938211510)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw5YiGjuH9pN"
      },
      "source": [
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"tf version:\",tf.__version__)\n",
        "\n",
        "print(\"keras version:\", keras.__version__)\n",
        "\n",
        "tf version: 2.6.0\n",
        "\n",
        "keras version: 2.6.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XAjNqIse9pJ"
      },
      "source": [
        "Therefore, below I first upload the TF nightly version. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5bmtFNee07h"
      },
      "source": [
        "```python\n",
        "tf version: 2.8.0-dev20211005\n",
        "keras version: 2.7.0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPRv2g92Polb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d9c690-2fa9-4138-eb9b-da1584071ab3"
      },
      "source": [
        "pip install tf-nightly --quiet --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 588.2 MB 20 kB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 43.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 439 kB 32.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 41.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsDBX1yETA3v"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RqP1sQpRhf5",
        "outputId": "07885769-16fb-4715-c898-b0bfd5dcbc35"
      },
      "source": [
        "print(\"tf version:\",tf.__version__)\n",
        "print(\"keras version:\", keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf version: 2.11.0-dev20221004\n",
            "keras version: 2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bPDDB871W56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50b0f5d-5b0f-4458-a92e-b034db5a7a7b"
      },
      "source": [
        "#@title Record Each Cell's Execution Time\n",
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.1\n",
            "time: 553 µs (started: 2022-10-04 13:47:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqcyE0LzKL-4"
      },
      "source": [
        "# 3. DOWNLOAD A KAGGLE DATASET INTO GOOGLE COLAB\n",
        "\n",
        "The [Multi Class Classification Dataset for Turkish](https://www.kaggle.com/savasy/multiclass-classification-data-for-turkish-tc32?select=ticaret-yorum.csv) is a **benchmark dataset for Turkish** **text classification** task. \n",
        "\n",
        "It contians 430K comments/reviews for a total 32 categories products or services.\n",
        "\n",
        "Each category roughly has 13K comments.\n",
        "\n",
        "A baseline algoritm, Naive Bayes, gets %84 F1 score.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[My blog post explaning how to download Kaggle Datasets is here.](https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a)\n",
        "\n",
        "My video tutorial explaning how to download Kaggle Datasets is here: [Turkish](https://youtu.be/ls47CPFU1vE)/[English](https://youtu.be/_rlt4mzLDLc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pIhSabUHQPB",
        "outputId": "d15d2e52-1863-442c-8605-2e89440fa147"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "time: 25.6 s (started: 2022-10-04 13:47:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyAOsTtRIaSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1116011-99be-4375-dbbd-24d2574fcd33"
      },
      "source": [
        "#os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 592 µs (started: 2022-10-04 13:48:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGE3TaZtIsIl",
        "outputId": "77bd60d2-97a2-429a-e1f9-e25711685f40"
      },
      "source": [
        "#changing the working directory\n",
        "%cd \"/content/gdrive/MyDrive/text_class\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/text_class\n",
            "time: 4.87 ms (started: 2022-10-04 13:48:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o__jkIwI-63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9fa0bb-45a2-4bea-8760-b729892db4f4"
      },
      "source": [
        "#get the api command from kaggle dataset page\n",
        "#!kaggle datasets download -d savasy/multiclass-classification-data-for-turkish-tc32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 476 µs (started: 2022-10-04 13:48:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cto_q1OUKQ9",
        "outputId": "2d31b143-d5aa-4069-bd7f-0e605e349014"
      },
      "source": [
        "# check the downloaded zip file\n",
        "!ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atr_july_sort_gds.csv  id_to_category.pkl  stopwords.txt\n",
            "time: 137 ms (started: 2022-10-04 13:48:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViTkX2CbLTUe",
        "outputId": "313ae77d-73db-4880-ea8d-5ab33efc5b1f"
      },
      "source": [
        "# unzipping the zip files and deleting the zip files\n",
        "#!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 519 µs (started: 2022-10-04 13:48:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvogE3ztLndZ",
        "outputId": "16d31c38-8a9d-4405-8823-d95142f3c086"
      },
      "source": [
        "# check the downloaded csv file\n",
        "!ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atr_july_sort_gds.csv  id_to_category.pkl  stopwords.txt\n",
            "time: 131 ms (started: 2022-10-04 13:48:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJakYWhG9W1"
      },
      "source": [
        "# 4. LOAD STOP WORDS IN TURKISH\n",
        "\n",
        "As you might know \"**Stop words**\" are a set of commonly used words in a language. Examples of stop words in **English** are “a”, “the”, “is”, “are” and etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to **eliminate** words that are so commonly used that they carry **very little useful information**.\n",
        "\n",
        "I begin with uploading an existing  list of stop words in Turkish below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y0t0dhJG77-",
        "outputId": "bc66fb1d-83c4-4c7c-a7d0-a92ad8e98f4a"
      },
      "source": [
        "tr_stop_words = pd.read_csv('stopwords.txt',header=None)\n",
        "for each in tr_stop_words.values[:5]:\n",
        "  print(each[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "about\n",
            "above\n",
            "across\n",
            "after\n",
            "time: 759 ms (started: 2022-10-04 13:48:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WQNplaQhmB3"
      },
      "source": [
        "# 5. LOAD THE DATASET\n",
        "After downloading the dataset from Kaggle website, we can upload it by using the Pandas library `read_csv()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v0as4QesGQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd0aad1-8d32-403c-fb0c-0f7101d38055"
      },
      "source": [
        "data1 = pd.read_csv('atr_july_sort_gds.csv')\n",
        "pd.set_option('max_colwidth', 400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 994 ms (started: 2022-10-04 13:48:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHr3M_p1ctKe"
      },
      "source": [
        "# **PART B: KNOW THE DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVGStvwEesYR"
      },
      "source": [
        "# 6. EXPLORE THE DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C0H8DoiguLw"
      },
      "source": [
        "Before getting into the details of how to use the `tf.keras.layers.TextVectorization` layer, let me introduce the dataset briefly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-eRYB-PlQsx"
      },
      "source": [
        "## Shuffle Data\n",
        "\n",
        "It is a really good and useful habit that, before doing anything else, as a first step in the preprocessing shuffle the data!\n",
        "\n",
        "Actually, I will shuffle the data at the last step of the pipeline.\n",
        "But it does not hurt shuffling it twice :))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIVvhLjlvYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491de81c-c2af-4704-d0a4-e4f5f97d4b2f"
      },
      "source": [
        "data1= data1.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.9 ms (started: 2022-10-04 13:48:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27UOqnurdk-B"
      },
      "source": [
        "## Summary Information about the dataset\n",
        "\n",
        "Get the initial information about the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2H1RqPks2tL",
        "outputId": "19b37cdc-4678-46df-8477-c711c990c555"
      },
      "source": [
        "data1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 49233 entries, 16476 to 25685\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Unnamed: 0          49233 non-null  int64 \n",
            " 1   Merchant Type Code  49233 non-null  int64 \n",
            " 2   Merchant Type Desc  47236 non-null  object\n",
            " 3   Merchant Location   49233 non-null  object\n",
            " 4   Merchant Type       49233 non-null  object\n",
            " 5   Tran Type Desc      49233 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 2.6+ MB\n",
            "time: 37.9 ms (started: 2022-10-04 13:49:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynP1CD8oVtv_"
      },
      "source": [
        "We have a total of **431306** of rows and **2** columns: ***category*** & ***text***.\n",
        "\n",
        "According to `data.info()`, there is **no null values** in the dataset. If there are any null values in the dataset, we could drop these null values as follows:\n",
        "```python\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df.isnull().sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31JouHmqVtCm"
      },
      "source": [
        "## Sample Reviews and their categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "rzfkiUERVz5O",
        "outputId": "2333f813-6d5b-4987-960d-dc4a22fb9428"
      },
      "source": [
        "data1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  Merchant Type Code                 Merchant Type Desc  \\\n",
              "16476      327604                5541                   Service Stations   \n",
              "36867      743933                6012             Financial Institutions   \n",
              "3019        53506                5399  Miscellaneous General Merchandise   \n",
              "2344        44022                5411        Grocery Stores Supermarkets   \n",
              "7696       141024                8220              Colleges Universities   \n",
              "\n",
              "                              Merchant Location Merchant Type  \\\n",
              "16476  MOHAN FILLING STATI 1  FARIDABAD    HRIN           POS   \n",
              "36867  CHOLAMANDALAM INVESTMENGUWAHATI     ASIN           ATM   \n",
              "3019   FLIPKART               Mumbai       MHIN          ECom   \n",
              "2344   VISHAL MEGA MART       VARANASI     UPIN           POS   \n",
              "7696   KIMS NEW               BHUBANESHWAR ORIN           POS   \n",
              "\n",
              "           Tran Type Desc  \n",
              "16476  Goods and services  \n",
              "36867  Goods and services  \n",
              "3019   Goods and services  \n",
              "2344   Goods and services  \n",
              "7696   Goods and services  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a8c2c01-c275-4ee8-a483-ac37fde807e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Merchant Type Code</th>\n",
              "      <th>Merchant Type Desc</th>\n",
              "      <th>Merchant Location</th>\n",
              "      <th>Merchant Type</th>\n",
              "      <th>Tran Type Desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16476</th>\n",
              "      <td>327604</td>\n",
              "      <td>5541</td>\n",
              "      <td>Service Stations</td>\n",
              "      <td>MOHAN FILLING STATI 1  FARIDABAD    HRIN</td>\n",
              "      <td>POS</td>\n",
              "      <td>Goods and services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36867</th>\n",
              "      <td>743933</td>\n",
              "      <td>6012</td>\n",
              "      <td>Financial Institutions</td>\n",
              "      <td>CHOLAMANDALAM INVESTMENGUWAHATI     ASIN</td>\n",
              "      <td>ATM</td>\n",
              "      <td>Goods and services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3019</th>\n",
              "      <td>53506</td>\n",
              "      <td>5399</td>\n",
              "      <td>Miscellaneous General Merchandise</td>\n",
              "      <td>FLIPKART               Mumbai       MHIN</td>\n",
              "      <td>ECom</td>\n",
              "      <td>Goods and services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2344</th>\n",
              "      <td>44022</td>\n",
              "      <td>5411</td>\n",
              "      <td>Grocery Stores Supermarkets</td>\n",
              "      <td>VISHAL MEGA MART       VARANASI     UPIN</td>\n",
              "      <td>POS</td>\n",
              "      <td>Goods and services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7696</th>\n",
              "      <td>141024</td>\n",
              "      <td>8220</td>\n",
              "      <td>Colleges Universities</td>\n",
              "      <td>KIMS NEW               BHUBANESHWAR ORIN</td>\n",
              "      <td>POS</td>\n",
              "      <td>Goods and services</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a8c2c01-c275-4ee8-a483-ac37fde807e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a8c2c01-c275-4ee8-a483-ac37fde807e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a8c2c01-c275-4ee8-a483-ac37fde807e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.1 ms (started: 2022-10-04 13:49:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqjl4QZHvAxK"
      },
      "source": [
        "# 7. CREATE A TENSORFLOW DATA PIPELINE FOR TEXT PREPROCESSING &  VECTORIZATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU26jUANffDY"
      },
      "source": [
        "So far, we just observe some properties of the **raw data**.\n",
        "Using these observations, we are ready to preprocess the `text` data for a classifier model.\n",
        "\n",
        "Below, we will begin to create a **TensorFlow data pipeline** which includes **Keras Text Vectorization layer** for preprocessing the data and preparing it for a classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfxrJ2-Agb7m"
      },
      "source": [
        "A pipeline for a text model mostly involves extracting symbols from raw text data, converting them to embedding identifiers with a lookup table, and batching together sequences of different lengths.\n",
        "\n",
        "In this tutorial, I will use the TensorFlow \"**tf.data**\" API. If you are not familiar with TF data pipeline \"**tf.data**\" API, you can apply below resources:\n",
        "* Official TensorFlow blog: [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data) \n",
        "* The Murat Karakaya Akademi YouTube playlist in Turkish: [tf.data: TensorFlow Data Pipeline Anlamak ve Kullanmak](https://www.youtube.com/playlist?list=PLQflnv_s49v8l8dYU01150vcoAn4sWSAm)  \n",
        "* The Murat Karakaya Akademi YouTube playlist in English:[TensorFlow Data Pipeline: How to Design Code Use TensorFlow Data Pipelines with Python & Keras](https://www.youtube.com/playlist?list=PLQflnv_s49v_m6KLMsORgs9hVIvDCwDAb)\n",
        "* The Murat Karakaya Akademi Medium blog: [tf.data: Tensorflow Data Pipelines](https://medium.com/deep-learning-with-keras/tf-data-tensorflow-data-pipelines-71915155bdf2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVSPJfBxlmN8"
      },
      "source": [
        "## Convert Categories From Strings to Integer Ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhGRDmGZjhBt"
      },
      "source": [
        "Observe that the categories (topics/class)of the reviews are **strings**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-2z9GHNiA8Y"
      },
      "source": [
        "We nned to create **integer** category **ids** from **string** category **names** by adding a new column to the dataframe \"**category_id**\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4MqVsZlix51"
      },
      "source": [
        "Lastly, we can check the number of categories. Note that it should be **32**: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd=pd.DataFrame(data1.groupby(['Merchant Type Code']).size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNDR-7ea-c9M",
        "outputId": "69e54da1-4a14-4051-a0f7-61e5e3391f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17.2 ms (started: 2022-10-04 13:49:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd.reset_index(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koSf9r5NCHdx",
        "outputId": "b10a08b6-c9bf-47cc-ce7e-1599ae06dfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.85 ms (started: 2022-10-04 13:49:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "i2iKK6m5C6cx",
        "outputId": "e6c3f73a-0aca-44f2-ab2d-8db20fba070a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Merchant Type Code     0\n",
              "0                   742     4\n",
              "1                   763     4\n",
              "2                   780     5\n",
              "3                  1520     1\n",
              "4                  1740     2\n",
              "..                  ...   ...\n",
              "201                8999    34\n",
              "202                9211    19\n",
              "203                9222     1\n",
              "204                9311     9\n",
              "205                9399  3144\n",
              "\n",
              "[206 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbaa2c10-3c76-4608-89ef-7af86ef0ec4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Merchant Type Code</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>742</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>763</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>780</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1520</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1740</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>8999</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>9211</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>9222</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>9311</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>9399</td>\n",
              "      <td>3144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>206 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbaa2c10-3c76-4608-89ef-7af86ef0ec4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbaa2c10-3c76-4608-89ef-7af86ef0ec4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbaa2c10-3c76-4608-89ef-7af86ef0ec4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17.8 ms (started: 2022-10-04 13:49:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g=[]\n",
        "for i in range(0,len(cd)):\n",
        "  if cd.iloc[i,1] < 2:\n",
        "    g.append(cd.iloc[i,0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgj0plxCDAKw",
        "outputId": "04691a3b-c2eb-45c4-8135-8b954e68dcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.73 ms (started: 2022-10-04 13:50:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpm_eXtJFSvy",
        "outputId": "a911e2b2-87b1-4e10-ff19-8b5c4b1d38a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1520,\n",
              " 1771,\n",
              " 3020,\n",
              " 3177,\n",
              " 3513,\n",
              " 3533,\n",
              " 3562,\n",
              " 3635,\n",
              " 3659,\n",
              " 4829,\n",
              " 5199,\n",
              " 5932,\n",
              " 5997,\n",
              " 7338,\n",
              " 7339,\n",
              " 7534,\n",
              " 7542,\n",
              " 7941,\n",
              " 7991,\n",
              " 8021,\n",
              " 8249,\n",
              " 9222]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.33 ms (started: 2022-10-04 13:50:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPa6sqNhNFpB",
        "outputId": "a0e898ab-2a4a-4aac-e378-2d2b609e6e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49233, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.8 ms (started: 2022-10-04 13:50:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = data1[~data1['Merchant Type Code'].isin(g)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQoeKh7tNFT1",
        "outputId": "2755bf88-ea53-4817-ae90-3d84eb70984a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.95 ms (started: 2022-10-04 13:50:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQEoF8adN2RA",
        "outputId": "2b312ab7-ef90-4d68-e8b1-8bbfdb993ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49211, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.99 ms (started: 2022-10-04 13:50:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGwGKS9-OFtp",
        "outputId": "cf93f251-0e73-49d9-8d12-02e60c59c839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 480 µs (started: 2022-10-04 13:50:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvGKtybDOL0O",
        "outputId": "43db0e4c-6a07-4681-f733-a13fba8aca65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49211, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.84 ms (started: 2022-10-04 13:50:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Merchant Type Code'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpudbyq-RD_7",
        "outputId": "1d4ad7f7-25ea-45fc-dd2f-be4c1c31dcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.74 ms (started: 2022-10-04 13:52:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Merchant Type Code\"] = data[\"Merchant Type Code\"].astype('category')\n",
        "data[\"category_id\"] = data[\"Merchant Type Code\"].cat.codes\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "csZ0BsJcOLeB",
        "outputId": "9694358c-caa2-48b8-cd76-1d9cc82b9e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0 Merchant Type Code                 Merchant Type Desc  \\\n",
              "16476      327604               5541                   Service Stations   \n",
              "36867      743933               6012             Financial Institutions   \n",
              "3019        53506               5399  Miscellaneous General Merchandise   \n",
              "2344        44022               5411        Grocery Stores Supermarkets   \n",
              "7696       141024               8220              Colleges Universities   \n",
              "\n",
              "                              Merchant Location Merchant Type  \\\n",
              "16476  MOHAN FILLING STATI 1  FARIDABAD    HRIN           POS   \n",
              "36867  CHOLAMANDALAM INVESTMENGUWAHATI     ASIN           ATM   \n",
              "3019   FLIPKART               Mumbai       MHIN          ECom   \n",
              "2344   VISHAL MEGA MART       VARANASI     UPIN           POS   \n",
              "7696   KIMS NEW               BHUBANESHWAR ORIN           POS   \n",
              "\n",
              "           Tran Type Desc  category_id  \n",
              "16476  Goods and services           65  \n",
              "36867  Goods and services          120  \n",
              "3019   Goods and services           54  \n",
              "2344   Goods and services           55  \n",
              "7696   Goods and services          170  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af37ea1a-883a-4cd0-a238-1b9909f6d7a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Merchant Type Code</th>\n",
              "      <th>Merchant Type Desc</th>\n",
              "      <th>Merchant Location</th>\n",
              "      <th>Merchant Type</th>\n",
              "      <th>Tran Type Desc</th>\n",
              "      <th>category_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16476</th>\n",
              "      <td>327604</td>\n",
              "      <td>5541</td>\n",
              "      <td>Service Stations</td>\n",
              "      <td>MOHAN FILLING STATI 1  FARIDABAD    HRIN</td>\n",
              "      <td>POS</td>\n",
              "      <td>Goods and services</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36867</th>\n",
              "      <td>743933</td>\n",
              "      <td>6012</td>\n",
              "      <td>Financial Institutions</td>\n",
              "      <td>CHOLAMANDALAM INVESTMENGUWAHATI     ASIN</td>\n",
              "      <td>ATM</td>\n",
              "      <td>Goods and services</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3019</th>\n",
              "      <td>53506</td>\n",
              "      <td>5399</td>\n",
              "      <td>Miscellaneous General Merchandise</td>\n",
              "      <td>FLIPKART               Mumbai       MHIN</td>\n",
              "      <td>ECom</td>\n",
              "      <td>Goods and services</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2344</th>\n",
              "      <td>44022</td>\n",
              "      <td>5411</td>\n",
              "      <td>Grocery Stores Supermarkets</td>\n",
              "      <td>VISHAL MEGA MART       VARANASI     UPIN</td>\n",
              "      <td>POS</td>\n",
              "      <td>Goods and services</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7696</th>\n",
              "      <td>141024</td>\n",
              "      <td>8220</td>\n",
              "      <td>Colleges Universities</td>\n",
              "      <td>KIMS NEW               BHUBANESHWAR ORIN</td>\n",
              "      <td>POS</td>\n",
              "      <td>Goods and services</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af37ea1a-883a-4cd0-a238-1b9909f6d7a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af37ea1a-883a-4cd0-a238-1b9909f6d7a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af37ea1a-883a-4cd0-a238-1b9909f6d7a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 20.4 ms (started: 2022-10-04 13:52:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsaO4v8Zj34I",
        "outputId": "91f46e3b-b2b1-4fec-949f-ccba89c70f78"
      },
      "source": [
        "max(list(data['category_id']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.8 ms (started: 2022-10-04 13:54:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHdF7xZguBJy"
      },
      "source": [
        "## Build a Dictionary for id to text category (topic) look-up:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwfM2IVJuDJx",
        "outputId": "d55b5d22-f937-4a50-9174-4ff5099a05b4"
      },
      "source": [
        "id_to_category = pd.Series(data['Merchant Type Code'].values,index=data.category_id).to_dict()\n",
        "id_to_category"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{65: 5541,\n",
              " 120: 6012,\n",
              " 54: 5399,\n",
              " 55: 5411,\n",
              " 170: 8220,\n",
              " 20: 4812,\n",
              " 123: 6300,\n",
              " 21: 4814,\n",
              " 10: 4112,\n",
              " 60: 5499,\n",
              " 52: 5311,\n",
              " 94: 5921,\n",
              " 87: 5812,\n",
              " 173: 8299,\n",
              " 108: 5965,\n",
              " 183: 9399,\n",
              " 69: 5621,\n",
              " 161: 7999,\n",
              " 97: 5942,\n",
              " 125: 6540,\n",
              " 88: 5813,\n",
              " 81: 5722,\n",
              " 23: 4899,\n",
              " 41: 5198,\n",
              " 89: 5814,\n",
              " 77: 5699,\n",
              " 86: 5811,\n",
              " 82: 5732,\n",
              " 115: 5983,\n",
              " 126: 7011,\n",
              " 64: 5533,\n",
              " 165: 8062,\n",
              " 58: 5451,\n",
              " 24: 4900,\n",
              " 103: 5948,\n",
              " 169: 8211,\n",
              " 180: 8999,\n",
              " 17: 4722,\n",
              " 157: 7994,\n",
              " 114: 5977,\n",
              " 91: 5816,\n",
              " 75: 5691,\n",
              " 93: 5912,\n",
              " 142: 7399,\n",
              " 13: 4214,\n",
              " 151: 7699,\n",
              " 96: 5941,\n",
              " 74: 5661,\n",
              " 172: 8244,\n",
              " 39: 5192,\n",
              " 124: 6513,\n",
              " 119: 5999,\n",
              " 99: 5944,\n",
              " 72: 5651,\n",
              " 31: 5072,\n",
              " 106: 5960,\n",
              " 28: 5047,\n",
              " 11: 4121,\n",
              " 34: 5111,\n",
              " 43: 5211,\n",
              " 14: 4215,\n",
              " 56: 5422,\n",
              " 9: 4111,\n",
              " 22: 4816,\n",
              " 153: 7832,\n",
              " 59: 5462,\n",
              " 18: 4784,\n",
              " 48: 5271,\n",
              " 134: 7299,\n",
              " 70: 5631,\n",
              " 37: 5137,\n",
              " 182: 9311,\n",
              " 100: 5945,\n",
              " 181: 9211,\n",
              " 154: 7911,\n",
              " 84: 5734,\n",
              " 33: 5094,\n",
              " 129: 7230,\n",
              " 146: 7538,\n",
              " 135: 7311,\n",
              " 122: 6211,\n",
              " 12: 4131,\n",
              " 66: 5571,\n",
              " 98: 5943,\n",
              " 78: 5712,\n",
              " 147: 7622,\n",
              " 30: 5065,\n",
              " 27: 5045,\n",
              " 57: 5441,\n",
              " 53: 5331,\n",
              " 46: 5261,\n",
              " 166: 8071,\n",
              " 5: 2741,\n",
              " 117: 5993,\n",
              " 140: 7392,\n",
              " 131: 7278,\n",
              " 138: 7372,\n",
              " 90: 5815,\n",
              " 101: 5946,\n",
              " 158: 7996,\n",
              " 62: 5521,\n",
              " 113: 5973,\n",
              " 61: 5511,\n",
              " 45: 5251,\n",
              " 174: 8398,\n",
              " 163: 8043,\n",
              " 50: 5309,\n",
              " 168: 8111,\n",
              " 128: 7221,\n",
              " 121: 6051,\n",
              " 95: 5940,\n",
              " 7: 3595,\n",
              " 71: 5641,\n",
              " 80: 5719,\n",
              " 167: 8099,\n",
              " 92: 5817,\n",
              " 73: 5655,\n",
              " 137: 7361,\n",
              " 164: 8050,\n",
              " 102: 5947,\n",
              " 110: 5969,\n",
              " 68: 5611,\n",
              " 25: 5013,\n",
              " 133: 7298,\n",
              " 152: 7829,\n",
              " 29: 5051,\n",
              " 109: 5968,\n",
              " 118: 5995,\n",
              " 63: 5532,\n",
              " 104: 5949,\n",
              " 159: 7997,\n",
              " 35: 5122,\n",
              " 178: 8734,\n",
              " 38: 5139,\n",
              " 179: 8931,\n",
              " 160: 7998,\n",
              " 150: 7641,\n",
              " 44: 5231,\n",
              " 130: 7277,\n",
              " 0: 742,\n",
              " 49: 5300,\n",
              " 26: 5039,\n",
              " 171: 8241,\n",
              " 83: 5733,\n",
              " 143: 7512,\n",
              " 149: 7631,\n",
              " 132: 7296,\n",
              " 42: 5200,\n",
              " 79: 5713,\n",
              " 144: 7523,\n",
              " 4: 1761,\n",
              " 162: 8011,\n",
              " 51: 5310,\n",
              " 8: 3747,\n",
              " 127: 7210,\n",
              " 141: 7394,\n",
              " 156: 7993,\n",
              " 177: 8699,\n",
              " 105: 5950,\n",
              " 136: 7349,\n",
              " 6: 2842,\n",
              " 116: 5992,\n",
              " 1: 763,\n",
              " 145: 7531,\n",
              " 47: 5262,\n",
              " 19: 4789,\n",
              " 175: 8641,\n",
              " 148: 7623,\n",
              " 155: 7929,\n",
              " 16: 4582,\n",
              " 139: 7375,\n",
              " 40: 5193,\n",
              " 32: 5085,\n",
              " 2: 780,\n",
              " 85: 5735,\n",
              " 36: 5131,\n",
              " 112: 5971,\n",
              " 3: 1740,\n",
              " 67: 5592,\n",
              " 111: 5970,\n",
              " 76: 5697,\n",
              " 15: 4511,\n",
              " 107: 5964,\n",
              " 176: 8661}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 45.8 ms (started: 2022-10-04 13:55:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class= max(list(id_to_category.keys()))+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRAbmmk99DAn",
        "outputId": "168d5f91-4e46-41b4-890a-0ec2dbfae4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 712 µs (started: 2022-10-04 13:55:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-8-MhyaR_oo",
        "outputId": "2f573855-d509-44e5-b43f-10c332693f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.3 ms (started: 2022-10-04 13:55:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AYZ7g0u1tEnt",
        "outputId": "e5dc2166-5638-4f18-ac2c-e98a51664bb4"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/text_class'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.62 ms (started: 2022-10-04 13:56:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnxVEIVctDHz",
        "outputId": "5885d9cf-d941-431e-816b-613ee3752c6f"
      },
      "source": [
        "import pickle\n",
        "pkl_file = open(\"id_to_category.pkl\", \"wb\")\n",
        "pickle.dump(id_to_category, pkl_file)\n",
        "pkl_file.close()\n",
        "\n",
        "pkl_file = open(\"id_to_category.pkl\", \"rb\")\n",
        "uploaded_id_to_category = pickle.load(pkl_file)\n",
        "print(uploaded_id_to_category)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{65: 5541, 120: 6012, 54: 5399, 55: 5411, 170: 8220, 20: 4812, 123: 6300, 21: 4814, 10: 4112, 60: 5499, 52: 5311, 94: 5921, 87: 5812, 173: 8299, 108: 5965, 183: 9399, 69: 5621, 161: 7999, 97: 5942, 125: 6540, 88: 5813, 81: 5722, 23: 4899, 41: 5198, 89: 5814, 77: 5699, 86: 5811, 82: 5732, 115: 5983, 126: 7011, 64: 5533, 165: 8062, 58: 5451, 24: 4900, 103: 5948, 169: 8211, 180: 8999, 17: 4722, 157: 7994, 114: 5977, 91: 5816, 75: 5691, 93: 5912, 142: 7399, 13: 4214, 151: 7699, 96: 5941, 74: 5661, 172: 8244, 39: 5192, 124: 6513, 119: 5999, 99: 5944, 72: 5651, 31: 5072, 106: 5960, 28: 5047, 11: 4121, 34: 5111, 43: 5211, 14: 4215, 56: 5422, 9: 4111, 22: 4816, 153: 7832, 59: 5462, 18: 4784, 48: 5271, 134: 7299, 70: 5631, 37: 5137, 182: 9311, 100: 5945, 181: 9211, 154: 7911, 84: 5734, 33: 5094, 129: 7230, 146: 7538, 135: 7311, 122: 6211, 12: 4131, 66: 5571, 98: 5943, 78: 5712, 147: 7622, 30: 5065, 27: 5045, 57: 5441, 53: 5331, 46: 5261, 166: 8071, 5: 2741, 117: 5993, 140: 7392, 131: 7278, 138: 7372, 90: 5815, 101: 5946, 158: 7996, 62: 5521, 113: 5973, 61: 5511, 45: 5251, 174: 8398, 163: 8043, 50: 5309, 168: 8111, 128: 7221, 121: 6051, 95: 5940, 7: 3595, 71: 5641, 80: 5719, 167: 8099, 92: 5817, 73: 5655, 137: 7361, 164: 8050, 102: 5947, 110: 5969, 68: 5611, 25: 5013, 133: 7298, 152: 7829, 29: 5051, 109: 5968, 118: 5995, 63: 5532, 104: 5949, 159: 7997, 35: 5122, 178: 8734, 38: 5139, 179: 8931, 160: 7998, 150: 7641, 44: 5231, 130: 7277, 0: 742, 49: 5300, 26: 5039, 171: 8241, 83: 5733, 143: 7512, 149: 7631, 132: 7296, 42: 5200, 79: 5713, 144: 7523, 4: 1761, 162: 8011, 51: 5310, 8: 3747, 127: 7210, 141: 7394, 156: 7993, 177: 8699, 105: 5950, 136: 7349, 6: 2842, 116: 5992, 1: 763, 145: 7531, 47: 5262, 19: 4789, 175: 8641, 148: 7623, 155: 7929, 16: 4582, 139: 7375, 40: 5193, 32: 5085, 2: 780, 85: 5735, 36: 5131, 112: 5971, 3: 1740, 67: 5592, 111: 5970, 76: 5697, 15: 4511, 107: 5964, 176: 8661}\n",
            "time: 738 ms (started: 2022-10-04 13:56:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aym0dhZz-byL"
      },
      "source": [
        "## Reduce the Size of the Dataset\n",
        "\n",
        "Since using a large dataset for **testing** your pipeline would take more time, you would prefer **take a portion** of the raw dataset as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhQjlJ9CCbO0",
        "outputId": "1f841a25-06b7-4511-9d4c-1b51b5d99291"
      },
      "source": [
        "#limit the number of samples to be used in testing the pipeline\n",
        "#data_size= 1000 #instead of 431306 \n",
        "#data= data[:data_size]\n",
        "#data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 350 µs (started: 2022-10-04 13:56:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt9KpOpKnMk7"
      },
      "source": [
        "## Split the Raw Dataset into Train and Test Datasets\n",
        "\n",
        "To prevent **data leakage** during preprocessing the text data, we need to split the text int Train and Test data sets. \n",
        "\n",
        "**Data leakage** refers to a mistake make by the creator of a machine learning model in which they accidentally share information between the test and training data-sets. Typically, when splitting a data-set into testing and training sets, the goal is to ensure that no data is shared between the two. This is because the test set’s purpose is to simulate real-world, unseen data. However, when evaluating a model, we do have full access to both our train and test sets, so it is up to us to ensure that no data in the training set is present in the test set.\n",
        "\n",
        "In our case, since we want to classify reviews, we have **not to use** test reviews in **text vectorization**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-qdVfWagEu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a49b37-5e71-4d7a-caed-b0151d3e60d5"
      },
      "source": [
        "# save features and targets from the 'data'\n",
        "features, targets = data['Merchant Location'], data['category_id']\n",
        "\n",
        "train_features, test_features, train_targets, test_targets = train_test_split(\n",
        "        features, targets,\n",
        "        train_size=0.8,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        shuffle = True,\n",
        "        stratify=targets\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 43.8 ms (started: 2022-10-04 13:56:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKuPtn1VoxnX"
      },
      "source": [
        "# Build the Train & Test TensorFlow Datasets\n",
        "\n",
        "First, we create **TensorFlow Datasets** from the raw Train Dataframe for further processing.\n",
        "\n",
        "Note that:\n",
        "1. **X**: input (text/reviews)\n",
        "2. **y**: target value (categories/topics/class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swV1vlGKocG_"
      },
      "source": [
        "**Observe that** we have **reviews in text** as input and **categories (topics) in integer** as target values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E5ba9Gjv0lb",
        "outputId": "ff365a14-1d86-4579-e14b-bb53027da450"
      },
      "source": [
        "train_features.values[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AJIO                   Mumbai       MHIN',\n",
              "       'DIAMOND SERVICE        KOLKATA      WBIN',\n",
              "       'SABHARWAL BROTHERS     CHANDOULI    UPIN',\n",
              "       'ABHINAV ANAND          BEGUSARAI    BIIN',\n",
              "       'SATYAM AUTOMOBILES     THANE        MAIN'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.03 ms (started: 2022-10-04 13:56:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJTyncnJwOe9",
        "outputId": "8b22151c-467c-4322-a4cf-0f51b81f8672"
      },
      "source": [
        "train_targets.values[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([82, 65, 31, 65, 65], dtype=int16)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.33 ms (started: 2022-10-04 13:56:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMwYNTks2WZS"
      },
      "source": [
        "## Prepare TensorFlow Datasets\n",
        "\n",
        "We convert the data stored in Pandas Data Frame into  a data stored in TensorFlow Data Set as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyNh1kCskjVY",
        "outputId": "0641a371-03d6-488b-ef7e-fa253e55d08d"
      },
      "source": [
        "# train X & y\n",
        "train_text_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(train_features.values, tf.string)\n",
        ") \n",
        "train_cat_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(train_targets.values, tf.int64),\n",
        "\n",
        ") \n",
        "# test X & y\n",
        "test_text_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(test_features.values, tf.string)\n",
        ") \n",
        "test_cat_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(test_targets.values, tf.int64),\n",
        "\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 153 ms (started: 2022-10-04 13:56:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9oAjlqipore"
      },
      "source": [
        "## Decide the dictionary size and the review size\n",
        "\n",
        "For preprocessing the text, we need to decide the **dictionary (vocabulary) size** and the **review (text) length**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2frnPx9C4wE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c26bf1-be7d-484c-db63-9a2e026f7293"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20K words\n",
        "max_len = 50  # Maximum review (text) size in words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 543 µs (started: 2022-10-04 13:56:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye1tSOhYdZeX"
      },
      "source": [
        "# **PART C: USE KERAS TEXT VECTORIZATION LAYER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiGIXHdKnpBX"
      },
      "source": [
        "# 8. PREPROCESS THE TEXT WITH THE KERAS `TEXTVECTORIZATION` LAYER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pK1RrG8rROz"
      },
      "source": [
        "\n",
        "\n",
        "## 8.1. Define your own `custom_standardization` function\n",
        "First, I define a function which will preprocess the given text.\n",
        "The `custom_standardization` function will convert the given string to a standart form by transforming the input applying several updates:\n",
        "* convert all characters to lowercase\n",
        "* remove special symbols, extra spaces, html tags, digits, and puctuations\n",
        "* remove stop wrods\n",
        "* replace the special Turkish letters with the corresponding English letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKLdLF0qQBH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8239e498-29b7-494c-e727-6cdd19f3451b"
      },
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "def custom_standardization(input_string):\n",
        "    \"\"\" Remove html line-break tags and handle punctuation \"\"\"\n",
        "    no_uppercased = tf.strings.lower(input_string, encoding='utf-8')\n",
        "    no_stars = tf.strings.regex_replace(no_uppercased, \"\\*\", \" \")\n",
        "    no_repeats = tf.strings.regex_replace(no_stars, \"devamını oku\", \"\")    \n",
        "    no_html = tf.strings.regex_replace(no_repeats, \"<br />\", \"\")\n",
        "    no_digits = tf.strings.regex_replace(no_html, \"\\w*\\d\\w*\",\"\")\n",
        "    no_punctuations = tf.strings.regex_replace(no_digits, f\"([{string.punctuation}])\", r\" \")\n",
        "    #remove stop words\n",
        "    no_stop_words = ' '+no_punctuations+ ' '\n",
        "    for each in tr_stop_words.values:\n",
        "      no_stop_words = tf.strings.regex_replace(no_stop_words, ' '+each[0]+' ' , r\" \")\n",
        "    no_extra_space = tf.strings.regex_replace(no_stop_words, \" +\",\" \")\n",
        "    #remove Turkish chars\n",
        "    no_I = tf.strings.regex_replace(no_extra_space, \"ı\",\"i\")\n",
        "    no_O = tf.strings.regex_replace(no_I, \"ö\",\"o\")\n",
        "    no_C = tf.strings.regex_replace(no_O, \"ç\",\"c\")\n",
        "    no_S = tf.strings.regex_replace(no_C, \"ş\",\"s\")\n",
        "    no_G = tf.strings.regex_replace(no_S, \"ğ\",\"g\")\n",
        "    no_U = tf.strings.regex_replace(no_G, \"ü\",\"u\")\n",
        "\n",
        "    return no_U"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.59 ms (started: 2022-10-04 13:57:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2L0siQkzHBI"
      },
      "source": [
        "Quickly verify that `custom_standardization` works: try it on a sample Turkish input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M2IQsBBuy-a",
        "outputId": "28a43d23-0734-452f-fb52-3646dd38492a"
      },
      "source": [
        "input_string = \"Bu Issız Öğlenleyin de;  şunu ***1 Pijamalı Hasta***, ve  Ancak İşte Yağız Şoföre Çabucak Güvendi...Devamını oku\"\n",
        "print(\"input:  \", input_string)\n",
        "output_string= custom_standardization(input_string)\n",
        "print(\"output: \", output_string.numpy().decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:   Bu Issız Öğlenleyin de;  şunu ***1 Pijamalı Hasta***, ve  Ancak İşte Yağız Şoföre Çabucak Güvendi...Devamını oku\n",
            "output:   bu issiz oglenleyin de sunu pijamali hasta ve ancak i̇ste yagiz sofore cabucak guvendi \n",
            "time: 396 ms (started: 2022-10-04 13:57:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkigEVBvjqmk"
      },
      "source": [
        "## 8.2. Configure the Keras `TextVectorization` layer\n",
        "\n",
        "To preprocess the text, I will use the Keras `TextVectorization` layer. \n",
        "\n",
        "```python\n",
        "tf.keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"whitespace\",\n",
        "    ngrams=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=None,\n",
        "    pad_to_max_tokens=False,\n",
        "    vocabulary=None,\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "The Keras `TextVectorization` layer processes each example in the dataset as follows:\n",
        "\n",
        "1. Standardize each example (usually lowercasing + punctuation stripping)\n",
        "\n",
        "2. Split each example into substrings (usually words)\n",
        "\n",
        "3. Recombine substrings into tokens (usually ngrams)\n",
        "\n",
        "4. Index tokens (associate a unique int value with each token)\n",
        "\n",
        "5. Transform each example using this index, either into a vector of ints or a dense float vector.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI50-CQ27X-G"
      },
      "source": [
        "Let's build our `TextVectorization` layer by providing:\n",
        "\n",
        "1. The `custom_standardization()` function for the `standardize` method (callable).\n",
        "2. The `vocab_size` as the `max_tokens` number: The `max_tokens` is the maximum size of the vocabulary that will be created from the dataset. If `None`, there is no cap on the size of the vocabulary. Note that this vocabulary contains 1 **OOV (Out Of Vocabulary)** token, so the effective number of tokens is (max_tokens - 1 - (1 if output_mode == \"int\" else 0)).\n",
        "3. The `int` keyword as the `output_mode`: Optional specification for the **output** of the layer. Values can be \n",
        "* \"**int**\", \n",
        "* \"**multi_hot**\", \n",
        "* \"**count**\" or \n",
        "* \"**tf_idf**\", \n",
        "\n",
        "Configuring the layer as follows: \n",
        "* \"**int**\": Outputs integer indices, one integer index per split string token. When output_mode == \"int\", 0 is reserved for masked locations; this reduces the vocab size to max_tokens - 2 instead of max_tokens - 1.\n",
        "\n",
        "* \"**multi_hot**\": Outputs a single int array per batch, of either vocab_size or max_tokens size, containing 1s in all elements where the token mapped to that index exists at least once in the batch item. \n",
        "\n",
        "* \"**count**\": Like \"multi_hot\", but the int array contains a count of the number of times the token at that index appeared in the batch item. \n",
        "\n",
        "* \"**tf_idf**\": Like \"multi_hot\", but the TF-IDF algorithm is applied to find the value in each token slot. \n",
        "\n",
        "For \"**int**\" output, any shape of input and output is supported. \n",
        "\n",
        "For **all other output modes**, currently only **rank 1 inputs** (and rank 2 outputs after splitting) are supported. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-8JyLj68M5j"
      },
      "source": [
        "4. output_sequence_length=max_len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbdKK8Uc4ko-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d5b533-2135-4ce5-b005-89d8b9476ec0"
      },
      "source": [
        "# Create a vectorization layer and adapt it to the text\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size+2,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_len,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 23.6 ms (started: 2022-10-04 13:57:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsc8CNBeldYR"
      },
      "source": [
        "## 8.3. Adapt the Keras `TextVectorization` layer with the **training** data set, (not test data set!) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNSv_ZM9lTKe"
      },
      "source": [
        "`TextVectorization` preprocessing layer has an internal state that can be computed based on a sample of the training data. That is, `TextVectorization` holds a **mapping** between **string** tokens and integer **indices**.\n",
        "\n",
        "Thus, we will ***adopt*** `TextVectorization` preprocessing layer **ONLY** to the **training** data.\n",
        "\n",
        "\n",
        "**Please note that:** To prevent and data leak, we **DO NOT** adopt `TextVectorization` preprocessing layer to the **whole** (***train & test***) data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8nd1qGXwy-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0162349b-64c2-4e2a-c356-935023a29515"
      },
      "source": [
        "vectorize_layer.adapt(train_features)\n",
        "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.9 s (started: 2022-10-04 13:57:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOyv5s64AD1J"
      },
      "source": [
        "Let's see some example conversions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQpBexwy5Fsy",
        "outputId": "a590598e-ac41-4bd6-9bb4-1d1479c1d6d8"
      },
      "source": [
        "print(\"vocab has the \", len(vocab),\" entries\")\n",
        "print(\"vocab has the following first 10 entries\")\n",
        "for word in range(10):\n",
        "  print(word, \" represents the word: \", vocab[word])\n",
        "\n",
        "for X in train_features[:2]:\n",
        "  print(\" Given raw data: \" )\n",
        "  print(X)\n",
        "  tokenized = vectorize_layer(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers: \" )\n",
        "  print (tokenized)\n",
        "  print(\" Text after Tokenized and Transformed: \")\n",
        "  transformed = \"\"\n",
        "  for each in tf.squeeze(tokenized):\n",
        "    transformed= transformed+ \" \"+ vocab[each]\n",
        "  print(transformed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab has the  11698  entries\n",
            "vocab has the following first 10 entries\n",
            "0  represents the word:  \n",
            "1  represents the word:  [UNK]\n",
            "2  represents the word:  upin\n",
            "3  represents the word:  mhin\n",
            "4  represents the word:  mumbai\n",
            "5  represents the word:  noida\n",
            "6  represents the word:  delhi\n",
            "7  represents the word:  brin\n",
            "8  represents the word:  hrin\n",
            "9  represents the word:  dlin\n",
            " Given raw data: \n",
            "AJIO                   Mumbai       MHIN\n",
            " Tokenized and Transformed to a vector of integers: \n",
            "tf.Tensor(\n",
            "[[1726    4    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]], shape=(1, 50), dtype=int64)\n",
            " Text after Tokenized and Transformed: \n",
            " ajio mumbai mhin                                               \n",
            " Given raw data: \n",
            "DIAMOND SERVICE        KOLKATA      WBIN\n",
            " Tokenized and Transformed to a vector of integers: \n",
            "tf.Tensor(\n",
            "[[821  13  70  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n",
            " Text after Tokenized and Transformed: \n",
            " diamond service kolkata wbin                                              \n",
            "time: 129 ms (started: 2022-10-04 13:57:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Jm91uo8GL9",
        "outputId": "a6b4884c-31ba-44be-8b55-35fd8a016c91"
      },
      "source": [
        "vocab[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'upin', 'mhin', 'mumbai']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.49 ms (started: 2022-10-04 13:58:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwLTEYa7a2aD"
      },
      "source": [
        "## 8.4. Save & Upload TextVectorization layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9geoLkTlzJD"
      },
      "source": [
        "Due to the facts that adapting the Keras `TextVectorization` layer on a large text dataset takes considerable amount of time and porting the adapted layer to a different deployment environment is a high possibility, it is good to know how to save and load it.\n",
        "\n",
        "How to save a Keras `TextVectorization` layer? \n",
        "\n",
        "[There are currently 2 ways of doing it](https://stackoverflow.com/questions/65103526/how-to-save-textvectorization-to-disk-in-tensorflow):\n",
        "* save the Keras `TextVectorization` layer in a Keras Model\n",
        "* save the Keras `TextVectorization` layer as a pickle file.\n",
        "\n",
        "In this tutorial, I will use the first approach as it is native to the TF/Keras environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhXnpHRDntyl"
      },
      "source": [
        "### 8.4.1. Ensure that you are on the correct directory path :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHwRco9l89C9",
        "outputId": "6fbb2809-d7d3-4a4d-859f-7552ae5dfccc"
      },
      "source": [
        "%cd ../models/\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '../models/'\n",
            "/content/gdrive/MyDrive/text_class\n",
            "atr_july_sort_gds.csv  id_to_category.pkl  stopwords.txt\n",
            "time: 149 ms (started: 2022-10-04 13:58:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcsxmgbFn33v"
      },
      "source": [
        "### 8.4.2. Create a temporary Keras `model` by adding the adapted Keras `TextVectorization` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRvfjtqQa8Wa",
        "outputId": "8b886a18-7e19-4c63-db5d-29880a41f7ce"
      },
      "source": [
        "# Create model.\n",
        "vectorize_layer_model = tf.keras.models.Sequential()\n",
        "vectorize_layer_model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "vectorize_layer_model.add(vectorize_layer)\n",
        "vectorize_layer_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 50)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 312 ms (started: 2022-10-04 13:58:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9MlEks0oG9S"
      },
      "source": [
        "## 8.4.3. Save the temporary model including the adapted Keras `TextVectorization` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA0p_Nz6kAyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630a9097-3a24-4628-fefb-0976f2ac1594"
      },
      "source": [
        "filepath = \"vectorize_layer_model\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 860 µs (started: 2022-10-04 13:58:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5CCEtKHkEEU",
        "outputId": "852a5d93-3f67-423d-d41a-9266f149b36b"
      },
      "source": [
        "vectorize_layer_model.save(filepath, save_format=\"tf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.5 s (started: 2022-10-04 13:58:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYEdEVkY6K27",
        "outputId": "ff4c4b65-cc48-447b-9631-20bb340a84ff"
      },
      "source": [
        "%ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atr_july_sort_gds.csv  stopwords.txt\n",
            "id_to_category.pkl     \u001b[0m\u001b[01;34mvectorize_layer_model\u001b[0m/\n",
            "time: 145 ms (started: 2022-10-04 13:58:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMRIAizqoQt5"
      },
      "source": [
        "### 8.4.4. Load the `vectorize_layer_model` back to chek if saving is succesfull"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-BtuFg-5-yL",
        "outputId": "4acc36d5-4dc2-40f5-d065-88b22087683c"
      },
      "source": [
        "loaded_vectorize_layer_model = tf.keras.models.load_model(filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.68 s (started: 2022-10-04 13:58:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06p5ZMh_ofxn"
      },
      "source": [
        "### 8.4.5 Retrieve the **loaded** Keras `TextVectorization` layer\n",
        "\n",
        "Here, you have 2 options:\n",
        "* use the `loaded_model.predicted()` method to use the Keras `TextVectorization` layer, or\n",
        "* get the Keras `TextVectorization` layer out of the `loaded_model` as below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMp7Hu7ipNSJ",
        "outputId": "fc8107d1-0164-41ba-f6ec-ac1d9972813c"
      },
      "source": [
        "loaded_vectorize_layer = loaded_vectorize_layer_model.layers[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.05 ms (started: 2022-10-04 13:59:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfsI9cVipSUD"
      },
      "source": [
        "### 8.4.6. Compare the original and loaded `TextVectorization` layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk2CVBAjcsEx",
        "outputId": "39c2f67d-e3d8-421a-b46d-e39b4282f353"
      },
      "source": [
        "loaded_vocab=loaded_vectorize_layer.get_vocabulary()\n",
        "print(\"original vocab has the \", len(vocab),\" entries\")\n",
        "print(\"loaded vocab has the   \", len(loaded_vocab),\" entries\")\n",
        "print(\"loaded vocab has the following first 10 entries\")\n",
        "for word in range(10):\n",
        "  print(word, \" represents the word: \")\n",
        "  print(vocab[word], \" in original vocab\")\n",
        "  print(loaded_vocab[word], \" in loaded vocab\")\n",
        "for X in train_features[:1]:\n",
        "  print(\" Given raw data: \" )\n",
        "  print(X)\n",
        "\n",
        "  tokenized = vectorize_layer(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers by the original vectorize layer:\" )\n",
        "  print (tokenized)\n",
        "\n",
        "  tokenized = loaded_vectorize_layer(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers by the loaded vectorize layer:\" )\n",
        "  print (tokenized)\n",
        "  \n",
        "  tokenized = loaded_vectorize_layer_model.predict(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers by the loaded_vectorize_layer_model:\" )\n",
        "  print (tokenized)\n",
        "\n",
        "  print(\" Text after Tokenized and Transformed by the original vectorize layer:: \")\n",
        "  transformed = \"\"\n",
        "  for each in tf.squeeze(tokenized):\n",
        "    transformed= transformed+ \" \"+ vocab[each]\n",
        "  print(transformed)\n",
        "\n",
        "  print(\" Text after Tokenized and Transformed by the loaded vectorize layer:\")\n",
        "  transformed = \"\"\n",
        "  for each in tf.squeeze(tokenized):\n",
        "    transformed= transformed+ \" \"+ loaded_vocab[each]\n",
        "  print(transformed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original vocab has the  11698  entries\n",
            "loaded vocab has the    11698  entries\n",
            "loaded vocab has the following first 10 entries\n",
            "0  represents the word: \n",
            "  in original vocab\n",
            "  in loaded vocab\n",
            "1  represents the word: \n",
            "[UNK]  in original vocab\n",
            "[UNK]  in loaded vocab\n",
            "2  represents the word: \n",
            "upin  in original vocab\n",
            "upin  in loaded vocab\n",
            "3  represents the word: \n",
            "mhin  in original vocab\n",
            "mhin  in loaded vocab\n",
            "4  represents the word: \n",
            "mumbai  in original vocab\n",
            "mumbai  in loaded vocab\n",
            "5  represents the word: \n",
            "noida  in original vocab\n",
            "noida  in loaded vocab\n",
            "6  represents the word: \n",
            "delhi  in original vocab\n",
            "delhi  in loaded vocab\n",
            "7  represents the word: \n",
            "brin  in original vocab\n",
            "brin  in loaded vocab\n",
            "8  represents the word: \n",
            "hrin  in original vocab\n",
            "hrin  in loaded vocab\n",
            "9  represents the word: \n",
            "dlin  in original vocab\n",
            "dlin  in loaded vocab\n",
            " Given raw data: \n",
            "AJIO                   Mumbai       MHIN\n",
            " Tokenized and Transformed to a vector of integers by the original vectorize layer:\n",
            "tf.Tensor(\n",
            "[[1726    4    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]], shape=(1, 50), dtype=int64)\n",
            " Tokenized and Transformed to a vector of integers by the loaded vectorize layer:\n",
            "tf.Tensor(\n",
            "[[1726    4    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]], shape=(1, 50), dtype=int64)\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            " Tokenized and Transformed to a vector of integers by the loaded_vectorize_layer_model:\n",
            "[[1726    4    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]]\n",
            " Text after Tokenized and Transformed by the original vectorize layer:: \n",
            " ajio mumbai mhin                                               \n",
            " Text after Tokenized and Transformed by the loaded vectorize layer:\n",
            " ajio mumbai mhin                                               \n",
            "time: 763 ms (started: 2022-10-04 13:59:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PopPGDc4p0fZ"
      },
      "source": [
        "As you see above, we succesfully saved and loaded the *adapted* Keras `TextVectorization` layer!\n",
        "\n",
        "We can continue to the TensorFlow datapipeline with the **adapted** Keras `TextVectorization` layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IuA1NfTflVVh",
        "outputId": "61d52ecd-757f-4967-dee6-7e793c125572"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/text_class'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.01 ms (started: 2022-10-04 13:59:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp0qIlQf0yym"
      },
      "source": [
        "# 9. APPLY KERAS `TEXTVECTORIZATION` TO TRAIN & TEST DATA SETS \n",
        "\n",
        "We can define a function to apply the Keras `TextVectorization` on a given string as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm1KFgd61PQs",
        "outputId": "682d9963-e610-4e5e-d9ea-d4f51d682c58"
      },
      "source": [
        "def convert_text_input(sample):\n",
        "    text = sample\n",
        "    text = tf.expand_dims(text, -1)  \n",
        "    #return tf.squeeze(vectorize_layer(text))\n",
        "    return tf.squeeze(loaded_vectorize_layer(text)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 853 µs (started: 2022-10-04 13:59:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0t4sIVH12qk"
      },
      "source": [
        "We use the TensorFlow `tf.data` API (TF Data Pipeline) `map()` funtion to apply `convert_text_input()` on every sample in the `text` column (reviews) of the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESBeHt831vwc",
        "outputId": "acd148fb-a872-47d3-d8fb-62265d1b5a05"
      },
      "source": [
        "# Train X\n",
        "train_text_ds = train_text_ds_raw.map(convert_text_input, \n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "# Test X\n",
        "test_text_ds = test_text_ds_raw.map(convert_text_input, \n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 828 ms (started: 2022-10-04 13:59:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6q3pkSZ2c2E"
      },
      "source": [
        "Let's see the converted/encoded texts (reviews)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVld41qV2kGZ",
        "outputId": "bf39f993-3f65-4815-8903-2e943718103e"
      },
      "source": [
        "for each in train_text_ds.take(3):\n",
        "  print(each)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[1726    4    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[821  13  70  28   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[3062  236 1573    2    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int64)\n",
            "time: 201 ms (started: 2022-10-04 13:59:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHvbhCZk2rsk"
      },
      "source": [
        "10. GENERATE THE TRAIN SET BY COMBINING X & Y:\n",
        "* **X**: the preprocessed & encoded reviews \n",
        "* **y**: encoded categories) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOYpCBmV2xTk",
        "outputId": "c3a723dd-f3bf-4f60-a181-06b5961e705a"
      },
      "source": [
        "train_ds = tf.data.Dataset.zip(\n",
        "    (\n",
        "            train_text_ds,\n",
        "            train_cat_ds_raw\n",
        "     )\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.82 ms (started: 2022-10-04 13:59:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS6Nje1IJi_D"
      },
      "source": [
        "Similarly, let's bundle test data sets as a single data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaQLHIYOJrng",
        "outputId": "92d3a5c4-b1be-4406-b94b-273d9544e55e"
      },
      "source": [
        "test_ds = tf.data.Dataset.zip(\n",
        "    (\n",
        "            test_text_ds,\n",
        "            test_cat_ds_raw\n",
        "     )\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.34 ms (started: 2022-10-04 13:59:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opoknhKL27Lr"
      },
      "source": [
        "We can see the result of the **Text Vectorization** in the **Data Pipelining** as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdqgVuiw3EOM",
        "outputId": "c5fa1e7c-633c-40fd-a8ba-ab45dc4a3412"
      },
      "source": [
        "for X,y in train_ds.take(1):\n",
        "  print(\"input (review) X.shape: \", X.shape)\n",
        "  print(\"output (category) y.shape: \", y.shape)\n",
        "  print(\"input (review) X: \", X)\n",
        "  print(\"output (category) y: \",y)\n",
        "  input = \" \".join([vocab[_] for _ in np.squeeze(X)])\n",
        "  output = id_to_category[y.numpy()]\n",
        "  print(\"X: input (review) in text: \" , input)\n",
        "  print(\"y: output (category) in text: \" , output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input (review) X.shape:  (50,)\n",
            "output (category) y.shape:  ()\n",
            "input (review) X:  tf.Tensor(\n",
            "[1726    4    3    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int64)\n",
            "output (category) y:  tf.Tensor(82, shape=(), dtype=int64)\n",
            "X: input (review) in text:  ajio mumbai mhin                                               \n",
            "y: output (category) in text:  5732\n",
            "time: 233 ms (started: 2022-10-04 13:59:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwBWJ_vQ3Q9d"
      },
      "source": [
        "# 11. FINALIZE TENSORFLOW DATA PIPELINE\n",
        "Finalize TensorFlow Data Pipeline by setting necessary parameters for batching, shuffling , and optimizing as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lODphjHX3STK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2928ed9f-b43f-4dc4-ac50-6ea8e72b5290"
      },
      "source": [
        "batch_size = 64\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size= train_ds.cardinality().numpy()\n",
        "\n",
        "train_ds = train_ds.shuffle(buffer_size=buffer_size)\\\n",
        "                   .batch(batch_size=batch_size,drop_remainder=True)\\\n",
        "                   .cache()\\\n",
        "                   .prefetch(AUTOTUNE)\n",
        "\n",
        "test_ds = test_ds.shuffle(buffer_size=buffer_size)\\\n",
        "                   .batch(batch_size=batch_size,drop_remainder=True)\\\n",
        "                   .cache()\\\n",
        "                   .prefetch(AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17.3 ms (started: 2022-10-04 13:59:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R4pk6MkUWCJ",
        "outputId": "7dfdf03b-37b2-40ac-943f-cfb646746b7d"
      },
      "source": [
        "train_ds.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=<unknown>, dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(64,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.73 ms (started: 2022-10-04 13:59:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQcMeCgkd4t6"
      },
      "source": [
        "# **PART D: BUILD AN END-TO-END MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD0PlXFiNSpa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67BIYNoP0E6v"
      },
      "source": [
        "# 12. Create a Classification Model\n",
        "\n",
        "For the sake of demonstration of the Keras `TextVectorization` layer, let's build a very simple model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2hK2ReMnHfz",
        "outputId": "7957ab7d-86b1-4742-e3e8-6db81faeae7e"
      },
      "source": [
        "def create_model():\n",
        "    inputs_tokens = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    embedding_layer = layers.Embedding(vocab_size, 256)\n",
        "    x = embedding_layer(inputs_tokens)\n",
        "    x = layers.Flatten()(x)\n",
        "    outputs = layers.Dense(num_class)(x) #no of input layers\n",
        "    model = keras.Model(inputs=inputs_tokens, outputs=outputs)\n",
        "    \n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    metric_fn  = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    model.compile(optimizer=\"adam\", loss=loss_fn, metrics=metric_fn)  \n",
        "    \n",
        "    return model\n",
        "my_model=create_model()\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 50, 256)           5120000   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 184)               2355384   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,475,384\n",
            "Trainable params: 7,475,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 493 ms (started: 2022-10-04 14:00:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtGgE1FxsRb"
      },
      "source": [
        "# 13. Train the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhiuaXoCxynm",
        "outputId": "d9368f45-4616-495e-bbe6-327e7d105ee5"
      },
      "source": [
        "my_model.fit(train_ds, verbose=1, epochs=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "615/615 [==============================] - 84s 105ms/step - loss: 1.5552 - sparse_categorical_accuracy: 0.6712\n",
            "Epoch 2/3\n",
            "615/615 [==============================] - 65s 106ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.8722\n",
            "Epoch 3/3\n",
            "615/615 [==============================] - 65s 105ms/step - loss: 0.3090 - sparse_categorical_accuracy: 0.9306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecec078050>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4min 49s (started: 2022-10-04 14:00:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGjnwq6SyUX-",
        "outputId": "a2839836-6b7a-4df0-b4fc-649a7b11ad0c"
      },
      "source": [
        "loss, accuracy = my_model.evaluate(test_ds)\n",
        "print(\"Train accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153/153 [==============================] - 7s 10ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.8799\n",
            "Train accuracy:  0.8799019455909729\n",
            "time: 6.58 s (started: 2022-10-04 14:05:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zlRPwlBx-L_"
      },
      "source": [
        "# 14. An End-To-End Classification Model\n",
        "\n",
        "Pay attention that the above model is expected to receive batches of integer tensors as input:\n",
        "\n",
        "```\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " input_3 (InputLayer)        [(None, 50)]              0         \n",
        "```\n",
        "Thus, you can NOT supply raw data (some text) to the model for prediction. TensorFlow/Keras would generate error message as below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "budX5NPuMOS5"
      },
      "source": [
        "```python\n",
        "raw_data=['Dün aldığım samsung telefon bugün şarj tutmuyor',\n",
        "          'THY Uçak biletimi değiştirmek için başvurdum.  Kimse geri dönüş yapmadı!']\n",
        "\n",
        "predictions=my_model.predict(raw_data)\n",
        "\n",
        "ValueError: in user code: Exception encountered when calling layer \"model\" (type Functional).\n",
        "    \n",
        "    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1of input shape to have value 12800, but received input with shape (None, 256)\n",
        "    \n",
        "    Call arguments received:\n",
        "      • inputs=tf.Tensor(shape=(None,), dtype=string)\n",
        "      • training=False\n",
        "      • mask=None\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpxyclVcM4hB"
      },
      "source": [
        "However, sometimes it a big advantage if we can design a model which accepts raw data as input, then, process the data by itself.\n",
        "\n",
        "For example such a model can be easily exported different platforms/environments without the need of exporting the preprocess code!\n",
        "\n",
        "Therefore, Keras provides [several Preprocessing Layers](https://keras.io/api/layers/preprocessing_layers/) so that we can integrate preprocessing logic as a layer into a Keras model.\n",
        "\n",
        "After then, we can export such models and use any other platforms without re-writing preprocessing code on the exported platforms/environments.\n",
        "\n",
        "This kind of models can be called **End-To-End Models**. That is, an **End-To-End model** can accept Raw Input Data and preprocess it by itself.\n",
        "\n",
        "**What could be Raw Data? **\n",
        "\n",
        "It could be:\n",
        "* text\n",
        "* image\n",
        "* structure data\n",
        "* etc.\n",
        "\n",
        "Let's create an **End-To-End Classification Model** by integrating the **adapted** Keras `TextVectorization` layer into the **trained model** as **the first layer**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQgRdLHXL5jT"
      },
      "source": [
        "You can create an **End-To-End Model** either by:\n",
        "* Keras Sequential API, or\n",
        "* Keras Functional API "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyHOxb210keN"
      },
      "source": [
        "## 14.1. Create an End-To-End Model with Keras Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1IhG3stoIAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04a86bb-c1f6-46bf-ee3d-400c45b5d7b1"
      },
      "source": [
        "end_to_end_model = tf.keras.Sequential([\n",
        "  keras.Input(shape=(1,), dtype=\"string\"),\n",
        "  vectorize_layer,\n",
        "  my_model,\n",
        "  layers.Activation('softmax')\n",
        "])\n",
        "\n",
        "end_to_end_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
        ")\n",
        "end_to_end_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 50)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " model (Functional)          (None, 184)               7475384   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 184)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,475,384\n",
            "Trainable params: 7,475,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 359 ms (started: 2022-10-04 14:05:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeaGKzNN0o3Q"
      },
      "source": [
        "## 14.2. Create an End-To-End Model with Keras Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkQNhhD8296z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a9662f-95f4-48c3-a0b8-3699ed9be251"
      },
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorize_layer(inputs)\n",
        "outputs = my_model(x)\n",
        "end_to_end_model = keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
        ")\n",
        "end_to_end_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 50)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " model (Functional)          (None, 184)               7475384   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,475,384\n",
            "Trainable params: 7,475,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 339 ms (started: 2022-10-04 14:05:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw0C0IvF28T9"
      },
      "source": [
        "## 14.3. Test the End-to-End model with Raw (Text) Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmydvPGg3adQ",
        "outputId": "cb342d5c-7c54-4448-c12f-5cd8ef41cafc"
      },
      "source": [
        "raw_data=['SWIGGY                 BANGALORE    KAIN','MS RAJEEV AUTO SERVICE Ranchi       JHIN']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_category[np.argmax(predictions[0])])\n",
        "print(id_to_category[np.argmax(predictions[1])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "5814\n",
            "5541\n",
            "time: 107 ms (started: 2022-10-04 15:08:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln_ydyp5yob6",
        "outputId": "b9ead6e4-d665-42bb-970c-f36789a7d38b"
      },
      "source": [
        "loss, accuracy = end_to_end_model.evaluate(test_features,test_targets)\n",
        "print(\"end_to_end_model accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308/308 [==============================] - 5s 13ms/step - loss: 3.3583 - accuracy: 0.8800\n",
            "end_to_end_model accuracy:  0.8800162672996521\n",
            "time: 6.24 s (started: 2022-10-04 14:10:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhhQiICa7e38"
      },
      "source": [
        "## 14.4. Save the End-to-End model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEsPYR4e4Ihh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87f9091-f352-4c00-c83e-de37e349be06"
      },
      "source": [
        "end_to_end_model.save(\"end_to_end_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.5 s (started: 2022-10-04 14:10:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KldU3Asf7kHV"
      },
      "source": [
        "## 14.5. Load the End-to-End model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLrdCADgng_D",
        "outputId": "f369cec1-417b-4745-f15c-49257877e7e0"
      },
      "source": [
        "#changing the working directory\n",
        "%cd \"/content/gdrive/MyDrive/text_class\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/text_class\n",
            "time: 18.7 ms (started: 2022-10-04 14:11:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrKKxntwlHom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f8839d-fbc3-409a-c950-0ccb5c35289d"
      },
      "source": [
        "loaded_end_to_end_model = tf.keras.models.load_model(\"end_to_end_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.6 s (started: 2022-10-04 14:11:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYFqCKDk7mxD"
      },
      "source": [
        "## 14.6. Test the Loaded End-to-End model with Raw (Text) Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgtRzOEg6led",
        "outputId": "f1c18391-88d9-4964-df21-5adabcdfa766"
      },
      "source": [
        "raw_data=['FLIPKART PAYMENTS      Bangalore    KAIN','indian oil']\n",
        "predictions=loaded_end_to_end_model.predict(raw_data)\n",
        "print(id_to_category[np.argmax(predictions[0])])\n",
        "print(id_to_category[np.argmax(predictions[1])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n",
            "7399\n",
            "5541\n",
            "time: 325 ms (started: 2022-10-04 15:14:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG0pj0Bv3LPW",
        "outputId": "ed2a5dc1-e6cb-4e3f-8108-cc98e82d4e00"
      },
      "source": [
        "loss, accuracy = loaded_end_to_end_model.evaluate(test_features,test_targets)\n",
        "print(\"loaded_end_to_end_model accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2696/2696 [==============================] - 41s 15ms/step - loss: 2.3971 - accuracy: 0.9494\n",
            "loaded_end_to_end_model accuracy:  0.9493751525878906\n",
            "time: 40.9 s (started: 2022-10-04 11:11:35 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcfd6oqiD9R_"
      },
      "source": [
        "# **PART E: SUMMARY**\n",
        "In this tutorial, we have learned:\n",
        "* What a Keras `TextVectorization` layer is\n",
        "* Why we need to use a Keras `TextVectorization` layer in Natural Languge Processing (NLP) tasks\n",
        "* How to employ a Keras `TextVectorization` layer in Text Preprocessing\n",
        "* How to integrate a Keras `TextVectorization` layer to a trained model\n",
        "* How to save and upload a Keras `TextVectorization` layer and a model with a Keras `TextVectorization` layer\n",
        "* How to integrate a Keras `TextVectorization` layer with TensorFlow Data Pipeline API (`tf.data`)\n",
        "* How to design, train, save, and load an End-to-End model using Keras `TextVectorization` layer\n",
        "\n",
        "All above topics are presented in a **multi-class text classification** context.\n",
        "\n",
        "If you like this tutorial, please follow the Murat Karakaya Akademi [YouTube channel](https://www.youtube.com/c/MuratKarakayaAkademi) and [Medium blog](https://kmkarakaya.medium.com/).\n",
        "\n",
        "**Thank you for your patience!**\n",
        "\n",
        "#Keep Deep Learning :)"
      ]
    }
  ]
}